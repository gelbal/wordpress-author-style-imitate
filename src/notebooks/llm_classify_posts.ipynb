{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils.helper import load_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore notebook warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_posts_from_json(author_name: str, output_dir: str = \"author_posts\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Read posts from the JSON file.\n",
    "\n",
    "    Args:\n",
    "        author_name (str): The name of the author.\n",
    "        output_dir (str): The name of the output directory.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries containing post data.\n",
    "    \"\"\"\n",
    "    # Use the project_root defined earlier\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "    data_dir = os.path.join(project_root, 'data', output_dir)\n",
    "\n",
    "    # Construct the full path to the JSON file\n",
    "    json_filename = os.path.join(data_dir, f\"{author_name}.json\")\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(json_filename):\n",
    "        raise FileNotFoundError(f\"The file {json_filename} does not exist.\")\n",
    "\n",
    "    with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "        posts = json.load(f)\n",
    "\n",
    "    return posts\n",
    "\n",
    "def save_posts_to_json(posts: List[Dict], author_name: str, output_dir: str = \"author_posts\"):\n",
    "    \"\"\"\n",
    "    Save posts back to the JSON file.\n",
    "\n",
    "    Args:\n",
    "        posts (List[Dict]): The list of post dictionaries to save.\n",
    "        author_name (str): The name of the author.\n",
    "        output_dir (str): The name of the output directory.\n",
    "    \"\"\"\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "    data_dir = os.path.join(project_root, 'data', output_dir)\n",
    "    json_filename = os.path.join(data_dir, f\"{author_name}.json\")\n",
    "\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(posts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def save_classified_posts(posts: List[Dict], author_name: str, output_dir: str = \"classified_posts\"):\n",
    "    \"\"\"\n",
    "    Save classified posts to a separate directory.\n",
    "\n",
    "    Args:\n",
    "        posts (List[Dict]): The list of classified post dictionaries.\n",
    "        author_name (str): The name of the author.\n",
    "        output_dir (str): The name of the output directory.\n",
    "    \"\"\"\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "    data_dir = os.path.join(project_root, 'data', output_dir)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # Filter only classified posts\n",
    "    classified_posts = [\n",
    "        post for post in posts\n",
    "        if 'confidential' in post and post.get('status') == 'publish'\n",
    "    ]\n",
    "\n",
    "    json_filename = os.path.join(data_dir, f\"{author_name}_classified.json\")\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(classified_posts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_processed_post_ids(posts: List[Dict]) -> set:\n",
    "    \"\"\"\n",
    "    Get the set of post IDs that have already been classified.\n",
    "\n",
    "    Args:\n",
    "        posts (List[Dict]): The list of post dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of post IDs that have been classified.\n",
    "    \"\"\"\n",
    "    return {post['post_ID'] for post in posts if 'confidential' in post}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ConfidentialityClassification(BaseModel):\n",
    "    is_confidential: bool\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0])\n",
    "            # My local model sometimes returns a 'properties' wrapper. But the content adheres to the schema.\n",
    "            if 'properties' in output_dict:\n",
    "                output_dict = output_dict['properties']\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": [replies[0]]}\n",
    "\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original one\n",
    "prompt_template = \"\"\"\n",
    "Analyze the following blog post and determine if it contains any confidential or sensitive information that should not be shared online. Create a complete, valid JSON object with your classification and reasoning.\n",
    "\n",
    "Blog post:\n",
    "Title: {{title}}\n",
    "Content: {{content}}\n",
    "\n",
    "Consider the following types of sensitive information:\n",
    "1. Personal identifiable information (PII)\n",
    "2. Financial data\n",
    "3. Trade secrets or proprietary information\n",
    "4. Unreleased product details\n",
    "5. Internal company strategies or plans\n",
    "6. Confidential client information\n",
    "7. Sensitive health information\n",
    "8. Login credentials or access codes\n",
    "\n",
    "Follow this JSON schema, but only return the actual instances without any additional schema definition:\n",
    "{{schema}}\n",
    "\n",
    "Make sure your response is a complete, valid JSON object (dict) and not a list. Ensure all opening brackets, braces, and quotes have matching closing ones.\n",
    "\n",
    "{% if invalid_replies and error_message %}\n",
    "  You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "  However, this doesn't comply with the format requirements from above and triggered this Python exception: {{error_message}}\n",
    "  Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest one\n",
    "prompt_template = \"\"\"\n",
    "Analyze the following blog post and determine if it contains any confidential or sensitive information that should not be shared online. Create a complete, valid JSON object with your classification and reasoning.\n",
    "\n",
    "Blog post:\n",
    "Title: {{title}}\n",
    "Content: {{content}}\n",
    "\n",
    "Guidelines for classification:\n",
    "1. Confidential information includes:\n",
    "   - Personal identifiable information (PII) such as full names, addresses, phone numbers, or email addresses of individuals who are not public figures\n",
    "   - Financial data such as account numbers, credit card details, or specific salary information\n",
    "   - Trade secrets or proprietary information about unreleased products or services\n",
    "   - Internal company strategies or plans not meant for public disclosure\n",
    "   - Confidential client information or details about private business relationships\n",
    "   - Sensitive health information about specific individuals\n",
    "   - Login credentials, access codes, or security vulnerabilities\n",
    "\n",
    "2. Non-confidential information includes:\n",
    "   - General knowledge or publicly available information\n",
    "   - Personal opinions or experiences that don't reveal sensitive details\n",
    "   - Information about released products or services\n",
    "   - General industry trends or publicly known business strategies\n",
    "   - Public figures' names or publicly known information about them\n",
    "   - General health advice or information not tied to specific individuals\n",
    "   - Technical information that is already in the public domain\n",
    "\n",
    "3. When in doubt, lean towards classifying the post as non-confidential unless there is clear sensitive information.\n",
    "\n",
    "4. Consider the context of the blog post. Information that might be sensitive in one context could be non-confidential in another.\n",
    "\n",
    "Follow this JSON schema for your response:\n",
    "{{schema}}\n",
    "\n",
    "Make sure your response is a complete, valid JSON object (dict) and not a list. Ensure all opening brackets, braces, and quotes have matching closing ones.\n",
    "\n",
    "{% if invalid_replies and error_message %}\n",
    "  You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "  However, this doesn't comply with the format requirements from above and triggered this Python exception: {{error_message}}\n",
    "  Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OutputValidator with the Pydantic model\n",
    "output_validator = OutputValidator(pydantic_model=ConfidentialityClassification)\n",
    "\n",
    "generator = OllamaGenerator(model=\"qwen2.5\",\n",
    "                            url = \"http://localhost:11434\",\n",
    "                            generation_kwargs={\n",
    "                            \"num_predict\": 100,\n",
    "                            \"temperature\": 0.7,\n",
    "                            })\n",
    "\n",
    "pipeline = Pipeline(max_loops_allowed=3)\n",
    "\n",
    "# Add components to the pipeline\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Connect the components\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_validator\")\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"prompt_builder.error_message\")\n",
    "\n",
    "pipeline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_score(post):\n",
    "    like_weight = 1\n",
    "    view_weight = 0.1\n",
    "    comment_weight = 2\n",
    "\n",
    "    return (\n",
    "        post.get('like_count', 0) * like_weight +\n",
    "        post.get('views', 0) * view_weight +\n",
    "        post.get('comment_count', 0) * comment_weight\n",
    "    )\n",
    "\n",
    "def get_top_posts(posts: List[Dict], n: int = 50) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get the top N posts based on engagement score.\n",
    "\n",
    "    Args:\n",
    "        posts (List[Dict]): List of post dictionaries.\n",
    "        n (int): Number of top posts to return. Default is 50.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Top N posts sorted by engagement score.\n",
    "    \"\"\"\n",
    "    # Filter posts\n",
    "    filtered_posts = [\n",
    "        post for post in posts\n",
    "        if post.get('status') == 'publish' and (post.get('confidential') is None or post.get('confidential') == False)\n",
    "    ]\n",
    "\n",
    "    # Sort posts by score in descending order\n",
    "    sorted_posts = sorted(filtered_posts, key=post_score, reverse=True)\n",
    "\n",
    "    # Return top N posts\n",
    "    return sorted_posts[:n]\n",
    "\n",
    "def process_author_posts(author_name: str):\n",
    "    print(f\"\\nProcessing posts for author: {author_name}\")\n",
    "    posts = read_posts_from_json(author_name)\n",
    "    processed_ids = get_processed_post_ids(posts)\n",
    "    top_posts = get_top_posts(posts, n=50)\n",
    "\n",
    "    for i, post in enumerate(top_posts):\n",
    "        if post['post_ID'] in processed_ids:\n",
    "            print(f\"Skipping already processed post {i+1}/{len(top_posts)}: {post['title']}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing post {i+1}/{len(top_posts)}: {post['title']}\")\n",
    "\n",
    "        input_dict = {\n",
    "            \"title\": post[\"title\"],\n",
    "            \"content\": post[\"content\"],\n",
    "            \"schema\": ConfidentialityClassification.schema_json()\n",
    "        }\n",
    "\n",
    "        result = pipeline.run(data=input_dict)\n",
    "\n",
    "        if result[\"output_validator\"][\"valid_replies\"]:\n",
    "            classification = json.loads(result[\"output_validator\"][\"valid_replies\"][0])\n",
    "            # My local model sometimes returns a 'properties' wrapper. But the content adheres to the schema.\n",
    "            if 'properties' in classification:\n",
    "                classification = classification['properties']\n",
    "            print(f\"Confidentiality classification: {classification}\")\n",
    "            post['confidential'] = classification['is_confidential']\n",
    "            post['confidentiality_reason'] = classification['reason']\n",
    "        else:\n",
    "            print(\"Failed to generate valid classification after maximum iterations.\")\n",
    "            post['confidential'] = 'cannot_classify'\n",
    "            post['confidentiality_reason'] = 'Classification failed'\n",
    "\n",
    "        # Save the updated posts after each classification\n",
    "        save_posts_to_json(posts, author_name)\n",
    "        save_classified_posts(posts, author_name)\n",
    "\n",
    "    print(f\"Processing completed for author: {author_name}\")\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "# Function to create HTML for a group of posts\n",
    "def create_group_html(title, color, urls):\n",
    "    html = f\"<h3 style='color: {color};'>{title}</h3>\"\n",
    "    if urls:\n",
    "        html += \"<ul>\"\n",
    "        for url in urls:\n",
    "            html += f\"<li><a href='{url}'>{url}</a></li>\"\n",
    "        html += \"</ul>\"\n",
    "    else:\n",
    "        html += \"<p>No posts in this category.</p>\"\n",
    "    return html\n",
    "\n",
    "def display_results(all_posts: List[Dict]):\n",
    "    confidential_posts = []\n",
    "    non_confidential_posts = []\n",
    "    unclassified_posts = []\n",
    "\n",
    "    for post in all_posts:\n",
    "        if 'confidential' in post:\n",
    "            url = post.get('URL', 'No URL available')\n",
    "            if post['confidential'] == True:\n",
    "                confidential_posts.append(url)\n",
    "            elif post['confidential'] == False:\n",
    "                non_confidential_posts.append(url)\n",
    "            else:\n",
    "                unclassified_posts.append(url)\n",
    "\n",
    "    result_html = (\n",
    "        create_group_html(\"Confidential Posts\", \"red\", confidential_posts) +\n",
    "        create_group_html(\"Non-Confidential Posts\", \"green\", non_confidential_posts) +\n",
    "        create_group_html(\"Unclassified Posts\", \"orange\", unclassified_posts)\n",
    "    )\n",
    "\n",
    "    display(HTML(result_html))\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Confidential Posts: {len(confidential_posts)}\")\n",
    "    print(f\"Non-Confidential Posts: {len(non_confidential_posts)}\")\n",
    "    print(f\"Unclassified Posts: {len(unclassified_posts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [\"author1\", \"author2\", \"author3\", \"author4\", \"author5\"]\n",
    "all_processed_posts = []\n",
    "for author in authors:\n",
    "    processed_posts = process_author_posts(author)\n",
    "    all_processed_posts.extend(processed_posts)\n",
    "\n",
    "display_results(all_processed_posts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordpress-style-imitate-nMcqOf0y-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
